# Dockerfile for isolated GEF/GDB dynamic analysis
# This container provides a sandboxed environment for running and tracing ARM binaries
#
# Usage:
#   docker build -t r2d2-gef -f Dockerfile.gef .
#   docker run --rm --read-only --network=none --memory=512m --cpus=1 \
#     -v /path/to/binary:/binary:ro -v /tmp/output:/output r2d2-gef /binary

FROM debian:bookworm-slim

LABEL maintainer="r2d2"
LABEL description="GEF/GDB dynamic analysis container for ARM binary tracing"

# Install required packages
RUN apt-get update && apt-get install -y --no-install-recommends \
    gdb \
    gdb-multiarch \
    python3 \
    python3-pip \
    qemu-user \
    qemu-user-static \
    libc6-arm64-cross \
    libc6-armhf-cross \
    libc6-mips64el-cross \
    libc6-mipsel-cross \
    ca-certificates \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install GEF (GDB Enhanced Features)
RUN curl -fsSL https://gef.blah.cat/sh -o /tmp/gef.sh && \
    bash /tmp/gef.sh && \
    rm /tmp/gef.sh

# Copy GEF configuration
RUN echo 'set auto-load safe-path /' >> /root/.gdbinit && \
    echo 'set pagination off' >> /root/.gdbinit && \
    echo 'set confirm off' >> /root/.gdbinit && \
    echo 'set logging overwrite on' >> /root/.gdbinit

# Create non-root user for running binaries
RUN useradd -m -s /bin/bash analyst && \
    mkdir -p /output && \
    chown analyst:analyst /output

# Copy analysis script
COPY --chmod=755 <<'EOF' /usr/local/bin/analyze_binary.py
#!/usr/bin/env python3
"""GEF analysis script for ARM binary tracing.

This script runs a binary under GDB with QEMU, collecting:
- Register snapshots at key points
- Memory maps
- Execution trace information
"""

import argparse
import json
import os
import subprocess
import sys
import tempfile
from pathlib import Path


def detect_architecture(binary_path: str) -> tuple[str, str]:
    """Detect binary architecture and return (qemu_cmd, gdb_arch)."""
    try:
        result = subprocess.run(
            ["file", "-b", binary_path],
            capture_output=True,
            text=True,
            timeout=5
        )
        output = result.stdout.lower()

        if "aarch64" in output or "arm64" in output:
            return "qemu-aarch64", "aarch64"
        elif "arm" in output:
            return "qemu-arm", "arm"
        elif "mips" in output:
            if "64" in output:
                return "qemu-mips64el", "mips64"
            return "qemu-mipsel", "mips"
        elif "x86-64" in output or "x86_64" in output:
            return "", "x86_64"  # Native, no QEMU needed
        elif "80386" in output or "i386" in output:
            return "qemu-i386", "i386"
        else:
            return "qemu-aarch64", "aarch64"  # Default to ARM64
    except Exception:
        return "qemu-aarch64", "aarch64"


def create_gdb_script(binary: str, output_file: str, max_instructions: int) -> str:
    """Generate GDB script for analysis."""
    return f'''
# GEF analysis script
set confirm off
set pagination off
set logging file {output_file}.log
set logging overwrite on
set logging redirect off
set logging enabled on

# Python script for data collection
python
import json
import gdb

class AnalysisData:
    def __init__(self):
        self.data = {{
            "binary": "{binary}",
            "entry_point": None,
            "register_snapshots": [],
            "memory_maps": [],
            "instruction_count": 0,
            "exit_code": None,
            "error": None
        }}

    def add_register_snapshot(self, pc, sp, regs):
        self.data["register_snapshots"].append({{
            "pc": pc,
            "sp": sp,
            "registers": regs
        }})

    def save(self, path):
        with open(path, "w") as f:
            json.dump(self.data, f, indent=2)

analysis = AnalysisData()

def get_registers():
    """Get current register values."""
    regs = {{}}
    try:
        frame = gdb.selected_frame()
        arch = frame.architecture()

        for reg in arch.registers():
            try:
                val = frame.read_register(reg)
                if val.type.code == gdb.TYPE_CODE_INT:
                    regs[reg.name] = int(val)
            except:
                pass
    except:
        pass
    return regs

def snapshot_registers():
    """Take a register snapshot."""
    regs = get_registers()
    pc = regs.get("pc", regs.get("rip", regs.get("eip", 0)))
    sp = regs.get("sp", regs.get("rsp", regs.get("esp", 0)))
    analysis.add_register_snapshot(pc, sp, regs)

# Get entry point
try:
    info = gdb.execute("info files", to_string=True)
    for line in info.split("\\n"):
        if "Entry point:" in line:
            entry = line.split(":")[-1].strip()
            analysis.data["entry_point"] = entry
            break
except:
    pass

end

# Start execution
start

# Snapshot at entry
python
snapshot_registers()
end

# Step through execution (limited)
python
step_count = 0
max_steps = {max_instructions}
snapshot_interval = max(1, max_steps // 10)  # 10 snapshots max

while step_count < max_steps:
    try:
        gdb.execute("stepi", to_string=True)
        step_count += 1

        # Take snapshots at intervals
        if step_count % snapshot_interval == 0:
            snapshot_registers()

    except gdb.error as e:
        if "exited" in str(e).lower() or "terminated" in str(e).lower():
            break
        # Ignore other errors and continue
        step_count += 1

analysis.data["instruction_count"] = step_count
end

# Final snapshot
python
snapshot_registers()
end

# Get memory maps
python
try:
    maps = gdb.execute("info proc mappings", to_string=True)
    lines = maps.strip().split("\\n")
    for line in lines[4:]:  # Skip header
        parts = line.split()
        if len(parts) >= 5:
            analysis.data["memory_maps"].append({{
                "start": parts[0],
                "end": parts[1],
                "size": parts[2] if len(parts) > 2 else "0",
                "offset": parts[3] if len(parts) > 3 else "0",
                "permissions": parts[4] if len(parts) > 4 else "",
                "name": parts[5] if len(parts) > 5 else ""
            }})
except Exception as e:
    pass
end

# Save results
python
analysis.save("{output_file}")
end

quit
'''


def run_analysis(binary: str, output_dir: str, max_instructions: int = 10000) -> dict:
    """Run GDB analysis on the binary."""
    binary_path = Path(binary)
    if not binary_path.exists():
        return {"error": f"Binary not found: {binary}"}

    qemu_cmd, gdb_arch = detect_architecture(binary)
    output_file = Path(output_dir) / "output.json"

    # Create GDB script
    script_content = create_gdb_script(binary, str(output_file), max_instructions)

    with tempfile.NamedTemporaryFile(mode='w', suffix='.gdb', delete=False) as f:
        f.write(script_content)
        script_path = f.name

    try:
        # Build GDB command
        if qemu_cmd:
            # Cross-architecture: use gdb-multiarch with QEMU
            cmd = [
                "gdb-multiarch",
                "-q",
                "-x", script_path,
                "--args", qemu_cmd, "-g", "1234", binary
            ]
            # Start QEMU in background with gdbserver
            qemu_proc = subprocess.Popen(
                [qemu_cmd, "-g", "1234", binary],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )

            # Connect GDB to QEMU
            cmd = [
                "gdb-multiarch",
                "-q",
                "-ex", f"target remote localhost:1234",
                "-x", script_path,
                binary
            ]
        else:
            # Native architecture
            cmd = [
                "gdb",
                "-q",
                "-x", script_path,
                binary
            ]

        # Run GDB
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=60,
            cwd=os.path.dirname(binary) or "/"
        )

        # Load results
        if output_file.exists():
            with open(output_file) as f:
                data = json.load(f)
                data["returncode"] = result.returncode
                return data
        else:
            return {
                "error": "Analysis output not generated",
                "stdout": result.stdout[-1000:] if result.stdout else "",
                "stderr": result.stderr[-1000:] if result.stderr else "",
                "returncode": result.returncode
            }

    except subprocess.TimeoutExpired:
        return {"error": "Analysis timed out"}
    except Exception as e:
        return {"error": str(e)}
    finally:
        os.unlink(script_path)
        if 'qemu_proc' in dir():
            qemu_proc.terminate()


def main():
    parser = argparse.ArgumentParser(description="Analyze ARM binary with GEF/GDB")
    parser.add_argument("binary", help="Path to the binary to analyze")
    parser.add_argument("--output", "-o", default="/output", help="Output directory")
    parser.add_argument("--max-instructions", "-m", type=int, default=10000,
                       help="Maximum instructions to trace")
    args = parser.parse_args()

    result = run_analysis(args.binary, args.output, args.max_instructions)

    # Write final output
    output_path = Path(args.output) / "output.json"
    with open(output_path, "w") as f:
        json.dump(result, f, indent=2)

    print(json.dumps(result, indent=2))
    sys.exit(0 if "error" not in result else 1)


if __name__ == "__main__":
    main()
EOF

# Set working directory
WORKDIR /work

# Default command
ENTRYPOINT ["/usr/local/bin/analyze_binary.py"]
CMD ["--help"]
